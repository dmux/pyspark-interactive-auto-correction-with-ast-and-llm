# ‚ö° PySpark Interactive Auto-Correction with AST

[![Python Version](https://img.shields.io/badge/python-3.13+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT) <!-- Ou outra licen√ßa, se aplic√°vel -->

Uma aplica√ß√£o web Streamlit projetada para ajudar desenvolvedores e cientistas de dados a testar, depurar e executar interativamente scripts PySpark, com corre√ß√£o autom√°tica de erros alimentada por LLM e manipula√ß√£o segura de caminhos de arquivos Parquet usando Abstract Syntax Trees (AST).

## Vis√£o Geral

Trabalhar com PySpark muitas vezes envolve leitura e escrita de arquivos (especialmente Parquet). Gerenciar caminhos de arquivos, lidar com erros de sintaxe ou de tempo de execu√ß√£o e testar rapidamente pequenas altera√ß√µes pode ser tedioso. Esta aplica√ß√£o visa simplificar esse processo, fornecendo:

1.  **Um editor de c√≥digo interativo:** Cole ou escreva seu script PySpark.
2.  **Execu√ß√£o em tempo real:** Veja a sa√≠da (stdout/stderr) do seu script PySpark enquanto ele roda.
3.  **Manipula√ß√£o segura de caminhos Parquet:** Usa AST para reescrever automaticamente caminhos relativos `.parquet()` para usar um diret√≥rio tempor√°rio seguro e isolado para cada execu√ß√£o, prevenindo a sobrescrita acidental de dados e garantindo a limpeza.
4.  **Auto-Corre√ß√£o por LLM:** Se o script falhar (erro de sintaxe, erro de tempo de execu√ß√£o), a aplica√ß√£o envia o c√≥digo e o erro para um modelo LLM configur√°vel (como GPT-4o-mini, GPT-4o) para sugerir uma corre√ß√£o.
5.  **Loop de Corre√ß√£o Iterativo:** Tenta executar o c√≥digo corrigido, repetindo o processo por um n√∫mero configur√°vel de tentativas at√© o sucesso ou atingir o limite.
6.  **Gerenciamento de Ambiente:** Cria e limpa automaticamente ambientes de execu√ß√£o tempor√°rios.

## Funcionalidades Principais

- **Editor de C√≥digo PySpark:** Use o editor Ace integrado com destaque de sintaxe Python.
- **Execu√ß√£o Interativa:** Execute scripts PySpark diretamente da interface web.
- **Streaming de Sa√≠da:** Veja logs `stdout` e `stderr` em tempo real.
- **Reescrita Autom√°tica de Caminhos (AST):**
  - Analisa o c√≥digo Python antes da execu√ß√£o.
  - Detecta chamadas `spark.read.parquet("caminho/relativo")` e `df.write.parquet("outro/caminho")`.
  - Reescreve os caminhos relativos para apontar para um diret√≥rio tempor√°rio √∫nico e absoluto (ex: `/tmp/temp_pyspark_st_run_xxxx/<caminho_original>`).
  - Garante o isolamento da execu√ß√£o e a seguran√ßa dos dados.
- **Corre√ß√£o por LLM (OpenAI):**
  - Integra-se com a API da OpenAI.
  - Envia c√≥digo com falha e mensagem de erro para o modelo selecionado.
  - Analisa a resposta do LLM para extrair o c√≥digo corrigido.
- **Loop de Tentativas Configur√°vel:** Defina quantas vezes o LLM deve tentar corrigir o c√≥digo.
- **Sele√ß√£o de Modelo LLM:** Escolha entre diferentes modelos da OpenAI (GPT-4o-mini, GPT-4o, etc.).
- **Gerenciamento de Ambiente Tempor√°rio:** Cria automaticamente um diret√≥rio tempor√°rio para cada execu√ß√£o e o limpa posteriormente.
- **Prepara√ß√£o de Dados de Entrada (Opcional):** Pode gerar automaticamente um arquivo `dados_entrada_raw.parquet` de exemplo no diret√≥rio tempor√°rio para scripts que esperam ler dados.
- **Interface Amig√°vel:** Constru√≠da com Streamlit para facilidade de uso.

## Demo YouTube

[![Watch the video](https://img.youtube.com/vi/gACeCyfCOK4/maxresdefault.jpg)](https://youtu.be/gACeCyfCOK4)

## Screenshots

### Editor, op√ß√µes de configura√ß√£o (API Key, Modelo, Tentativas), bot√µes.

![Screenshot Main Interface](./screenshots/screenshot_main_interface.png)

### A √°rea de sa√≠da em tempo real com logs do PySpark.

![Screenshot Execution Log](./screenshots/screenshot_execution_log.png)

### Um erro (ex: SyntaxError) capturado na sa√≠da.

![Screenshot Error Detection](./screenshots/screenshot_error_detection.png)

### A sugest√£o de c√≥digo corrigido fornecida pelo LLM.

![Screenshot LLM Correction](./screenshots/screenshot_llm_correction.png)

### Uma execu√ß√£o bem-sucedida ap√≥s a corre√ß√£o.

![Screenshot Success Run](./screenshots/screenshot_success_run.png)

## Como Funciona

1.  **Entrada do Usu√°rio:** O usu√°rio insere ou edita o c√≥digo PySpark no editor Ace.
2.  **Configura√ß√£o:** O usu√°rio fornece a chave da API OpenAI e seleciona o modelo LLM e o n√∫mero m√°ximo de tentativas.
3.  **Prepara√ß√£o do Ambiente (Ao clicar em "Corrigir e Executar"):**
    - Um diret√≥rio tempor√°rio √∫nico √© criado no diret√≥rio tempor√°rio do sistema (ex: `/tmp/`).
    - (Opcional) Um arquivo Parquet de exemplo (`dados_entrada_raw.parquet`) √© gerado dentro deste diret√≥rio tempor√°rio.
4.  **Loop de Tentativa (Itera√ß√£o 1 a N):**
    - **An√°lise AST e Reescrita:** O c√≥digo _atual_ (original ou corrigido pelo LLM da tentativa anterior) √© analisado usando o m√≥dulo `ast` do Python. O `ParquetPathRewriter` visita a √°rvore e modifica n√≥s de chamada `.parquet()` que usam strings literais de caminho relativo, substituindo-os por caminhos absolutos dentro do diret√≥rio tempor√°rio da execu√ß√£o atual.
    - **Salvar Script Modificado:** O c√≥digo resultante _ap√≥s a reescrita AST_ √© salvo em um arquivo `.py` tempor√°rio.
    - **Execu√ß√£o:** O script `.py` modificado √© executado como um subprocesso (`subprocess.Popen`) usando o mesmo interpretador Python do Streamlit. `stdout` e `stderr` s√£o capturados em tempo real.
    - **Verifica√ß√£o de Sa√≠da:** O c√≥digo de sa√≠da do subprocesso √© verificado.
    - **Sucesso:** Se o c√≥digo de sa√≠da for 0, o loop termina com sucesso.
    - **Falha:** Se o c√≥digo de sa√≠da for diferente de 0 e o n√∫mero m√°ximo de tentativas n√£o foi atingido:
      - O _c√≥digo original_ da tentativa atual (antes da reescrita AST) e a _sa√≠da completa_ (stdout + stderr) s√£o enviados para a API da OpenAI (usando o modelo selecionado).
      - A resposta do LLM √© processada para extrair o bloco de c√≥digo Python corrigido.
      - Se uma corre√ß√£o v√°lida e diferente for recebida, o `current_code` √© atualizado com a sugest√£o do LLM para a _pr√≥xima_ itera√ß√£o do loop.
      - Se o LLM falhar, retornar o mesmo c√≥digo ou nenhuma corre√ß√£o, o loop √© interrompido.
    - **Feedback em Tempo Real:** A sa√≠da `stdout`/`stderr` √© exibida usando `st.code` dentro de um `st.empty()` para atualiza√ß√µes ao vivo. Mensagens de status e o c√≥digo a ser executado/corrigido s√£o mostrados em `st.expander` para cada tentativa.
5.  **Resultado Final:** Uma mensagem de sucesso ou falha geral √© exibida.
6.  **Limpeza:** O diret√≥rio tempor√°rio criado na etapa 3 √© removido, juntamente com todos os arquivos Parquet gerados e scripts tempor√°rios.

## Requisitos

- **Python:** 3.9 ou superior (devido ao uso de `ast.unparse`)
- **Java Development Kit (JDK):** PySpark requer uma instala√ß√£o Java funcional (geralmente JDK 8 ou 11+). Certifique-se de que `JAVA_HOME` esteja configurado corretamente em seu ambiente.
- **Bibliotecas Python:**
  - `streamlit`
  - `pandas`
  - `pyarrow` (para manipula√ß√£o de Parquet)
  - `openai` (cliente oficial da OpenAI)
  - `pyspark`
  - `streamlit-ace` (para o editor de c√≥digo)

## Instala√ß√£o e Configura√ß√£o

1.  **Clone o Reposit√≥rio (se aplic√°vel):**
    ```bash
    git clone <url-do-seu-repositorio>
    cd <diretorio-do-repositorio>
    ```
2.  **Crie um Ambiente Virtual (Recomendado):**
    ```bash
    python -m venv venv
    source venv/bin/activate  # Linux/macOS
    # ou
    venv\Scripts\activate    # Windows
    ```
3.  **Instale as Depend√™ncias:**
    Crie um arquivo `requirements.txt` com o seguinte conte√∫do:
    ```txt
    streamlit
    pandas
    pyarrow
    openai>=1.0 # Use uma vers√£o recente
    pyspark>=3.0 # Escolha uma vers√£o compat√≠vel
    streamlit-ace
    ```
    Ent√£o instale:
    ```bash
    pip install -r requirements.txt
    ```
4.  **Obtenha uma Chave da API OpenAI:** Voc√™ precisar√° de uma chave v√°lida da API OpenAI. Visite [platform.openai.com](https://platform.openai.com/) para obter uma.
5.  **Verifique a Instala√ß√£o do Java:** Certifique-se de que o Java (JDK) est√° instalado e a vari√°vel de ambiente `JAVA_HOME` est√° configurada corretamente para que o PySpark possa encontr√°-lo.

## Como Usar

1.  **Execute a Aplica√ß√£o Streamlit:**
    ```bash
    streamlit run seu_script_streamlit.py
    ```
    (Substitua `seu_script_streamlit.py` pelo nome do seu arquivo Python principal).
2.  **Abra no Navegador:** O Streamlit geralmente abrir√° a aplica√ß√£o automaticamente no seu navegador padr√£o ou fornecer√° um URL local (ex: `http://localhost:8501`).
3.  **Insira a Chave da API:** Cole sua chave da API OpenAI no campo correspondente na interface. A chave **n√£o** √© armazenada pela aplica√ß√£o.
4.  **Configure (Opcional):** Selecione o modelo LLM desejado e ajuste o controle deslizante para o n√∫mero m√°ximo de tentativas de corre√ß√£o.
5.  **Adicione seu C√≥digo PySpark:** Cole seu script PySpark no editor ou modifique o c√≥digo de exemplo fornecido.
    - **Importante:** Use **caminhos relativos** para quaisquer opera√ß√µes de leitura ou escrita de Parquet que voc√™ deseja que a aplica√ß√£o gerencie (ex: `spark.read.parquet("data/input")`, `df.write.parquet("results")`). Caminhos absolutos n√£o ser√£o reescritos.
6.  **Execute:** Clique no bot√£o "üöÄ Corrigir e Executar".
7.  **Observe:** Acompanhe o progresso na se√ß√£o "Processamento e Tentativas". Cada tentativa ser√° exibida em um expansor, mostrando o c√≥digo executado (ap√≥s reescrita AST), a sa√≠da em tempo real e, se ocorrer falha, a tentativa de corre√ß√£o do LLM.
8.  **Limpeza Manual (Opcional):** Use o bot√£o "üßπ Limpar Diret√≥rio Tempor√°rio Atual" se precisar remover manualmente o diret√≥rio tempor√°rio de uma execu√ß√£o anterior que pode n√£o ter sido limpa corretamente (raro).

## Solu√ß√£o de Problemas (Troubleshooting)

- **Erro de Chave da API OpenAI:** Verifique se a chave est√° correta, ativa e se sua conta tem cr√©ditos/quota suficientes.
- **PySpark n√£o inicia (`SparkSession` falha):**
  - Confirme se o Java (JDK) est√° instalado corretamente.
  - Verifique se a vari√°vel de ambiente `JAVA_HOME` est√° definida e aponta para a instala√ß√£o correta do JDK.
  - Certifique-se de que as vari√°veis `PYSPARK_PYTHON` e `PYSPARK_DRIVER_PYTHON` (definidas no script) apontam para o execut√°vel Python correto (especialmente dentro de ambientes virtuais).
- **LLM n√£o corrige o erro:**
  - O erro pode ser muito complexo para o modelo/prompt atual.
  - O modelo pode estar atingindo limites de taxa ou outros problemas da API.
  - Tente um modelo mais avan√ßado (ex: GPT-4o em vez de GPT-4o-mini).
  - O erro pode n√£o estar claramente representado na sa√≠da `stderr`/`stdout` capturada.
- **Problemas de Caminho Parquet:**
  - Certifique-se de estar usando caminhos _relativos_ no seu c√≥digo PySpark para que o reescritor AST funcione.
  - Verifique os logs da aplica√ß√£o Streamlit (console onde voc√™ executou `streamlit run`) para mensagens do `ParquetPathRewriter` se suspeitar de problemas na reescrita.
- **Erros de Depend√™ncia:** Certifique-se de que todas as bibliotecas listadas em `requirements.txt` foram instaladas corretamente no ambiente virtual ativo.
- **Erro `ast.unparse`:** Confirme que voc√™ est√° executando com Python 3.9 ou superior.

## Contribui√ß√µes

Contribui√ß√µes s√£o bem-vindas! Sinta-se √† vontade para abrir issues para relatar bugs ou sugerir melhorias. Se desejar contribuir com c√≥digo, por favor, abra um Pull Request.

## Licen√ßa

Este projeto est√° licenciado sob a Licen√ßa MIT. Veja o arquivo `LICENSE` para mais detalhes (ou escolha outra licen√ßa).
